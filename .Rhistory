getwd()
library(Rcpp)
install.packages("Rcpp")
library(Rcpp)
Rcpp.package.skeleton( "skycalc" )
Rcpp::compileAttributes()
library(parallel)
devtools::document()
install.packages("devtools")
library(devtools)
detach("package:usethis", unload = TRUE)
library(usethis)
install.packages(Rtsne)
install.packages("Rtsne")
usethis::use_package(package = "stats", type = "Imports")
usethis::use_package(package = "Rtsne", type = "Imports")
devtools::document()
?MAC
X <- matrix(rnorm(100), 10, 10)
Y <- rnorm(10, 1, 1)
X2 <- X
Y2 <- rnorm(10, 2, 2)
MAC(X, Y, X2, Y2)
devtools::document()
X <- matrix(rnorm(100), 10, 10)
Y <- X %*% rnorm(10, 5, 1) + rnorm(10)
model <- lm(Y ~ X - 1)
Y2 <- predict(model, newdata = data.frame(X))
ps_continuous(X, Y, Y2)
#' @param X The predictors in the training set, which is an n times p dimensional matrix.
#' @param Y The true response in the training set, which is an n-dimensional vector.
#' @param Y2 The prediction results of the trained model on the training set X.
#' @param BootNumber The number of bootstrap steps in the calculation of p_s.
#' @param cores The number of threads used for parallel computing.
#'
#' @returns The structure improvement index p_s. If p_s < 0.05, the model fit is not good enough and we need to increase the complexity of the model.
#' @export
#'
#' @examples
ps_continuous <- function(X, Y, Y2, BootNumber = 1000, cores = 10) {
BootStrapTb <- function(Predictor, TrueValue, Estimator, BootNumber, cores) {
eta <- TrueValue - Estimator
if(is.vector(eta)) {
n <- length(eta)
}else {
n <- dim(eta)[1]
}
if(n > 2000) {
k <- 200
}else {
k <- max(c(100, n))
}
boot_tb <- function(boot, Predictor, TrueValue, Estimator, eta, n, k) {
set.seed(boot + 100)
eta_star <- sample(eta, n, replace = TRUE)
Y2 <- Estimator + eta_star
set.seed(boot + 99)
eta_star2 <- sample(eta, n, replace = TRUE)
Y22 <- Estimator + eta_star2
mac1 <- MAC(Predictor, TrueValue, Predictor, Y2, k)
mac2 <- MAC(Predictor, Y22, Predictor, Y2, k)
return(c(mac1, mac2))
}
Tb <- parallel::mclapply(1:BootNumber, boot_tb, Predictor = Predictor,
TrueValue = TrueValue, Estimator = Estimator, eta = eta, n = n, k = k, mc.cores = cores)
Tb <- do.call(rbind, Tb)
return(Tb)
}
Tb <- BootStrapTb(X, Y, Y2, BootNumber)
T0 <- mean(Tb[, 1])
null_t <- Tb[, 2]
P <- (sum(null_t >= T0) + 1) / (BootNumber + 1)
return(P)
}
ps_continuous(X, Y, Y2)
#' @param X The predictors in the training set, which is an n times p dimensional matrix.
#' @param Y The true response in the training set, which is an n-dimensional vector.
#' @param Y2 The prediction results of the trained model on the training set X.
#' @param BootNumber The number of bootstrap steps in the calculation of p_s.
#' @param cores The number of threads used for parallel computing.
#'
#' @returns The structure improvement index p_s. If p_s < 0.05, the model fit is not good enough and we need to increase the complexity of the model.
#' @export
#'
#' @examples
ps_continuous <- function(X, Y, Y2, BootNumber = 1000, cores = 10) {
BootStrapTb <- function(Predictor, TrueValue, Estimator, BootNumber, cores) {
eta <- TrueValue - Estimator
if(is.vector(eta)) {
n <- length(eta)
}else {
n <- dim(eta)[1]
}
if(n > 2000) {
k <- 200
}else {
k <- max(c(100, n))
}
boot_tb <- function(boot, Predictor, TrueValue, Estimator, eta, n, k) {
set.seed(boot + 100)
eta_star <- sample(eta, n, replace = TRUE)
Y2 <- Estimator + eta_star
set.seed(boot + 99)
eta_star2 <- sample(eta, n, replace = TRUE)
Y22 <- Estimator + eta_star2
mac1 <- MAC(Predictor, TrueValue, Predictor, Y2, k)
mac2 <- MAC(Predictor, Y22, Predictor, Y2, k)
return(c(mac1, mac2))
}
Tb <- parallel::mclapply(1:BootNumber, boot_tb, Predictor = Predictor,
TrueValue = TrueValue, Estimator = Estimator, eta = eta, n = n, k = k, mc.cores = cores)
Tb <- do.call(rbind, Tb)
return(Tb)
}
Tb <- BootStrapTb(X, Y, Y2, BootNumber, cores)
T0 <- mean(Tb[, 1])
null_t <- Tb[, 2]
P <- (sum(null_t >= T0) + 1) / (BootNumber + 1)
return(P)
}
ps_continuous(X, Y, Y2)
ps_continuous(X, Y, Y2, 100, 1)
ps_continuous(X, Y, Y2, 10, 1)
#' @param X The predictors in the training set, which is an n times p dimensional matrix.
#' @param Y The true response in the training set, which is an n-dimensional vector.
#' @param Y2 The prediction results of the trained model on the training set X.
#' @param BootNumber The number of bootstrap steps in the calculation of p_s.
#' @param cores The number of threads used for parallel computing.
#'
#' @returns The structure improvement index p_s. If p_s < 0.05, the model fit is not good enough and we need to increase the complexity of the model.
#' @export
#'
#' @examples
ps_continuous <- function(X, Y, Y2, BootNumber = 1000, cores = 10) {
BootStrapTb <- function(Predictor, TrueValue, Estimator, BootNumber, cores) {
eta <- TrueValue - Estimator
if(is.vector(eta)) {
n <- length(eta)
}else {
n <- dim(eta)[1]
}
if(n > 2000) {
k <- 200
}else {
k <- min(c(100, n))
}
boot_tb <- function(boot, Predictor, TrueValue, Estimator, eta, n, k) {
set.seed(boot + 100)
eta_star <- sample(eta, n, replace = TRUE)
Y2 <- Estimator + eta_star
set.seed(boot + 99)
eta_star2 <- sample(eta, n, replace = TRUE)
Y22 <- Estimator + eta_star2
mac1 <- MAC(Predictor, TrueValue, Predictor, Y2, k)
mac2 <- MAC(Predictor, Y22, Predictor, Y2, k)
return(c(mac1, mac2))
}
Tb <- parallel::mclapply(1:BootNumber, boot_tb, Predictor = Predictor,
TrueValue = TrueValue, Estimator = Estimator, eta = eta, n = n, k = k, mc.cores = cores)
Tb <- do.call(rbind, Tb)
return(Tb)
}
Tb <- BootStrapTb(X, Y, Y2, BootNumber, cores)
T0 <- mean(Tb[, 1])
null_t <- Tb[, 2]
P <- (sum(null_t >= T0) + 1) / (BootNumber + 1)
return(P)
}
ps_continuous(X, Y, Y2, 10, 1)
warnings()
#' @param k To speed up the calculation, when n is too large, you can specify to randomly extract k data points to calculate the MAC statistic.
#'
#' @returns The MAC statistic between two (X, Y) and (X2, Y2).
#' @export
#'
#' @examples X <- matrix(rnorm(100), 10, 10)
#'    Y <- rnorm(10, 1, 1)
#'    X2 <- X
#'    Y2 <- rnorm(10, 2, 2)
#'    MAC(X, Y, X2, Y2)
MAC <- function(X, Y, X2, Y2, k = NULL) {
if(is.vector(X)) {
X <- as.matrix(X, ncol = 1)
X2 <- as.matrix(X2, ncol = 1)
}
if(is.vector(Y)) {
Y <- as.matrix(Y, ncol = 1)
Y2 <- as.matrix(Y2, ncol = 1)
}
n <- dim(X)[1]
m <- dim(X2)[2]
if(is.null(k)) {
k <- n
list_i <- seq(1, n)
list_j <- seq((n+1), (n + m))
}else if(k < n) {
list_i <- order(X[1:n, 1])[round(seq(1, n, length.out = k))]
list_j <- order(X2[1:m, 1])[round(seq(1, m, length.out = k))]
list_j <- list_j + n
}else if(k == n) {
list_i <- seq(1, n)
list_j <- seq((n+1), (n + m))
}else {
stop("k must be smaller than n")
}
mac <- compute_MAC(rbind(X, X2), rbind(Y, Y2), list_i, list_j, n)
return(mac)
}
ps_continuous(X, Y, Y2, 10, 1)
warnings()
Y2 <- as.matrix(Y2, ncol = 1)
ps_continuous(X, Y, Y2, 10, 1)
ps_continuous(X, Y, Y2, 20, 1)
X <- matrix(rnorm(2000), 100, 20)
tmp <- X %*% rnorm(20) + rnorm(20)
probabilities <- 1 / (1 + exp(-tmp))
Y <- rbinom(100, 1, probabilities)
model <- glm(Y ~ X - 1, family = binomial)
predicted_probabilities <- predict(model, newdata = data.frame(X), type = "response")
ps_probs(X, Y, predicted_probabilities, 1, 100)
#' @returns The structure improvement index p_s. If p_s < 0.05, the model fit is not good enough and we need to increase the complexity of the model.
#' @export
#'
#' @examples X <- matrix(rnorm(2000), 100, 20)
#'     tmp <- X %*% rnorm(20) + rnorm(20)
#'     probabilities <- 1 / (1 + exp(-tmp))
#'     Y <- rbinom(100, 1, probabilities)
#'     model <- glm(Y ~ X - 1, family = binomial)
#'     predicted_probabilities <- predict(model, newdata = data.frame(X), type = "response")
#'     ps_probs(X, Y, predicted_probabilities, 1, 100)
ps_probs <- function(X, Y, predicted_probs, cores = 1, BootNumber = 1000) {
boot_tb <- function(boot, X, Y, predicted_probs) {
set.seed(boot + 100)
Y2 <- rbinom(length(Y), 1, predicted_probs)
set.seed(boot + 101)
Y22 <- rbinom(length(Y), 1, predicted_probs)
mac1 <- MAC(X, Y, X, Y2)
mac2 <- MAC(X, Y22, X, Y2)
return(c(mac1, mac2))
}
Tb <- parallel::mclapply(seq(1, BootNumber), FUN = boot_tb, X,
Y, predicted_probs, mc.cores = cores)
Tb <- do.call(rbind, Tb)
T0 <- mean(Tb[, 1])
null_t <- Tb[, 2]
P <- (sum(null_t >= T0) + 1) / (BootNumber + 1)
return(P)
}
ps_probs(X, Y, predicted_probabilities, 1, 100)
X_train <- matrix(rnorm(2000), 200, 10)
X_test <- matrix(rnorm(1000, 4, 2), 100, 10)
coverage_ratio(X_train, X_test)
X_test <- matrix(rnorm(1000, 1), 100, 10)
coverage_ratio(X_train, X_test)
devtools::document()
X <- matrix(rnorm(100), 10, 10)
Y <- X \%*\% rnorm(10, 5, 1) + rnorm(10)
X <- matrix(rnorm(100), 10, 10)
Y <- X %*% rnorm(10, 5, 1) + rnorm(10)
Y2 <- predict(model, newdata = data.frame(X))
model <- lm(Y ~ X - 1)
Y2 <- predict(model, newdata = data.frame(X))
Y2 <- as.matrix(Y2, ncol = 1)
ps_continuous(X, Y, Y2, 1, 100)
ps_continuous(X, Y, Y2, 100, 1)
q()
